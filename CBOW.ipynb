{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMVrELylg6Ab"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,Lambda,Dense\n",
        "import keras.backend as K\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras import utils"
      ],
      "metadata": {
        "id": "5gtpsuyujcJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=open('CBOW.txt','r')\n",
        "c_data=[text for text in data if text.count(' ')>=2]\n",
        "c_data"
      ],
      "metadata": {
        "id": "jj6nNiZ1hZWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer=Tokenizer()\n",
        "vectorizer.fit_on_texts(c_data)\n",
        "c_data=vectorizer.texts_to_sequences(c_data)"
      ],
      "metadata": {
        "id": "cbaQ-Rq6hZYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_vocab=sum(len(s) for s in c_data)\n",
        "word_count=len(vectorizer.word_index)+1\n",
        "window_size=2\n",
        "total_vocab\n",
        "word_count"
      ],
      "metadata": {
        "id": "jCS1g9qnhZbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cbow_model(data,window_size,total_vocab):\n",
        "  total_length=window_size*2\n",
        "  for text in data:\n",
        "    text_len=len(text)\n",
        "    for idx,word in enumerate(text):\n",
        "      context=[]\n",
        "      target=[]\n",
        "      begin=idx-window_size\n",
        "      end=idx+window_size+1\n",
        "      context.append([text[i] for i in range(begin,end) if 0<=i<text_len and i!=idx])\n",
        "      target.append(word)\n",
        "      contextual=sequence.pad_sequences(context,total_length)\n",
        "      final_target=utils.to_categorical(target,total_vocab)\n",
        "      yield(contextual,final_target)"
      ],
      "metadata": {
        "id": "CdJeTu2uiW3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(input_dim=total_vocab,output_dim=100,input_length=window_size*2))\n",
        "model.add(Lambda(lambda x: K.mean(x,axis=1),output_shape=(100,)))\n",
        "model.add(Dense(total_vocab,activation='softmax'))"
      ],
      "metadata": {
        "id": "DZpnQPNxjjl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crooentropy',optimizer='adam')"
      ],
      "metadata": {
        "id": "IY49BTJjjjoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  cost=0\n",
        "  for x,y in cbow_model(data,window_size,total_vocab):\n",
        "    cost+=model.train_on_batch(x,y)"
      ],
      "metadata": {
        "id": "X6P7_r4RkMak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions=100\n",
        "vect_file=open('vector.txt','w')\n",
        "vect_file.write('{}  {}\\n'.format(total_vocab,dimensions))"
      ],
      "metadata": {
        "id": "tCobT2wskZtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights=model.get_weights()[0]\n",
        "for text,i in vectorizer.word_index.items():\n",
        "  final_vec=' '.join(map(str,list(weights[i, :])))\n",
        "  vect_file.write('{} {}\\n'.format(text,final_vec))\n",
        "vect_file.close()"
      ],
      "metadata": {
        "id": "8umXFDGZkoFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cbow_model=gensim.models.KeyedVectors.load_word2vec_format('vector.txt',binary=False,limit=100)"
      ],
      "metadata": {
        "id": "4S7pSCJXkoH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cbow_model.most_similar(positive=['virus'])"
      ],
      "metadata": {
        "id": "7sAH1QVZmAtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B_O4vVS5mAv0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}